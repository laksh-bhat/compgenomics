
3.  This problem can be solved in linear time using a generalized suffix tree. The idea - every substring is a prefix
    of some suffix in the GST.
    There are 2 different ways I can think of building this suffix tree. (Idea from wikipedia article on GST)
    We could append a different character end marker ($1, $2 etc in general but for our problem we could do with just
    the '$' for all strings in set S)to all strings in S and concatenate them. We use this as text to be encoded in the
    GST. We know that the GST can be built in O(n + k), where k comes from the extra '$' at the end of each string.
    (A similar but different approach would be to add strings individually to the GST where each leaf is labeled by a
    pair (i,j), where 'i' identifies the string and 'j' is the start position in S_i.)
    We can then search GST for each string in O(k1), O(k2) ... O(Kk) respectively. During our substring search for the
    original strings (without $) we just have to see that we have at least 2 different branches after the last character,
    one for $ and remaining characters of other string/s.
    We can easily see that the worst case complexity for this approach is O(n+k/*GST*/ + n/*search*/) which is O(n),
    given K1 + K2 + ... + Kk = n

    The other approach is to build an implicit suffix tree using Ukkonenn's algorithm without concatenation.
    Lets assume for the sake of clarity (without loss of generality) that k = 2. Let the two string be S1 and S2.
    Construct suffix tree for S1. Start at the root of the tree and match S2's characters until we have a mismatch.
    Clearly, at this point the tree encodes all suffixes of S2 until current index, say i. This matching essentially
    is the first 'i' steps of Ukkonen's algorithm. We can now continue with the algorithm for the rest of the
    characters in S2. This tree now encodes all characters of S1 and S2. This tree is constructed in O(|S1| + |S2|).
    Generalizing this to k strings gives us a suffix tree built in O(n) where K1 + K2 + ... + Kk = n.
    Searching such a GST can be carried out in the usual manner in O(|k1| + |k2| + ... + |Kk|) = O(n).

4  a.
    ++++++++++++++++++++++++++++++++++++++++++++++++++++
    Pattern string 		  => circumstance
    No. of Exact Matches  => 45
    No. of OneMisMatches  => 1
    Specificity           => 0.195

    Pattern string 		  => expectations
    No. of Exact Matches  => 1
    No. of OneMisMatches  => 23
    Specificity           => 0.116

    Pattern string 		  => handkerchief
    No. of Exact Matches  => 34
    No. of OneMisMatches  => 2
    Specificity           => 0.462
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++

4  b. Short answer, pigeon hole principle.
      Long answer, Since we partition the pattern string into k+1 "pigeon holes", our algorithm makes sure that at least
      one of this is an exact match (by looking up the index). Once we hit an index we search the neighborhood for 0
      and 1 mismatches. Only then do we adjudge the text at this index to be a match.

4  c.
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++
    Pattern string 			=> performances
    No. of 0 mismatches 	=> 3
    No. of 1 mismatches 	=> 16
    No. of 2 mismatches 	=> 1
    Specificity 			=> 0.033

    Pattern string 			=> discontented
    No. of 0 mismatches 	=> 14
    No. of 1 mismatches 	=> 0
    No. of 2 mismatches 	=> 24
    Specificity 			=> 0.052
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++
5. a.
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++
    Pattern string 			=> circumstance
    No. of 0 mismatches 	=> 45
    No. of 1 mismatches 	=> 1
    Specificity 			=> 0.505

    Pattern string 			=> expectations
    No. of 0 mismatches 	=> 1
    No. of 1 mismatches 	=> 23
    Specificity 			=> 0.96


    Pattern string 			=> handkerchief
    No. of 0 mismatches 	=> 34
    No. of 1 mismatches 	=> 2
    Specificity 			=> 0.514

    Pattern string 			=> discontented
    No. of 0 mismatches 	=> 14
    No. of 1 mismatches 	=> 0
    Specificity 			=> 0.452

    Pattern string 			=> performances
    No. of 0 mismatches 	=> 3
    No. of 1 mismatches 	=> 16
    Specificity 			=> 0.826
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++

5  b. Yes! There is a huge improvement in specificity when we employ the "spaced-seed" scheme.
      We spend more time indexing but it pays off since the index to match conversion ration is very very high
      i.e. very few false positives. This is because the fingerprint generated by the subsequence finding
      algorithm is highly specific to the text - represents the text with high degree of confidence, so to speak.
      In our example, the language (english) has a pattern - characters occur with a known frequency and order
      and hence the fingerprint generated by the earlier index (4a) was generic and hit several parts of the text
      without much success. But if the text were truly random, one would expect both the indexes to be just as good/
      bad performant as the other.